{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4608a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "\n",
    "from GraphDataset import RandomGraphDataset\n",
    "from GraphToSequence import graphToSequence, sequenceToGraph\n",
    "\n",
    "from SimpleTransformer import SimpleTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5255a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_training = \"/eos/user/c/czeh/graphsequencer/fixed_edge_graph_training\"\n",
    "data_folder_test = \"/eos/user/c/czeh/graphsequencer/fixed_edge_graph_test\"\n",
    "\n",
    "\n",
    "dataset_training = RandomGraphDataset(data_folder_training, nodes=100, edges=20, data_count=1000)\n",
    "dataset_test = RandomGraphDataset(data_folder_test, nodes=100,  edges=20, data_count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b6cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_list_to_char_tensor(strings, char_to_index=None, max_len=-1):\n",
    "    \"\"\"Converts a list of strings to a character-level encoded tensor.\n",
    "\n",
    "    Args:\n",
    "        strings: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A LongTensor where each row represents a string, and each element\n",
    "        in the row is the character index.  Returns None if the input\n",
    "        list is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    if not strings:\n",
    "        return None\n",
    "\n",
    "    if not char_to_index:\n",
    "        # 1. Create a vocabulary (mapping char -> index)\n",
    "        all_chars = sorted(list(set(\"\".join(strings))))  # Unique characters\n",
    "        char_to_index = {char: index for index, char in enumerate(all_chars)}\n",
    "\n",
    "    # 2. Determine maximum string length for padding\n",
    "    if max_len <= 0:\n",
    "        max_len = max(len(s) for s in strings)\n",
    "\n",
    "    # 3. Create the tensor\n",
    "    tensor = torch.zeros(len(strings), max_len, dtype=torch.long)  # Initialize with padding (0)\n",
    "\n",
    "    # 4. Populate the tensor\n",
    "    for i, string in enumerate(strings):\n",
    "        for j, char in enumerate(string):\n",
    "            tensor[i, j] = char_to_index[char]\n",
    "\n",
    "    return char_to_index, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78d8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples, sequence, sequence_length):\n",
    "    idx = np.random.randint(0, len(seq)-3, (num_samples,))\n",
    "    vals = [seq[idx[i]:idx[i]+sequence_length+1] for i in idx]\n",
    "    char_to_index, inputs = string_list_to_char_tensor(vals)\n",
    "    inputs = torch.randint(0, vocab_size, (num_samples, sequence_length))\n",
    "    return char_to_index, inputs[:,:-1], inputs[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f295df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tensor_to_string_list(char_to_index, list):\n",
    "    index_to_char = {index: char for char, index in char_to_index.items()}\n",
    "    for row in char_tensor:\n",
    "        decoded_string = \"\".join([index_to_char[idx.item()] for idx in row if idx != 0]) #Ignore padding (0)\n",
    "        print(decoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9369278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9ef91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d753d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: plot the training loss and save to a file\n",
    "plot_training_loss = True\n",
    "\n",
    "# Check for GPU availability\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "# Hyperparameters\n",
    "seq = \"4.8.;13.11.(12.6.(7.9.10.5.*6.3.1.2.*11.))\"\n",
    "embed_size = 512\n",
    "sequence_length = 12\n",
    "vocab_size = 14  # Simple vocab size for demonstration\n",
    "num_samples = 10000\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1bc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, loss, and optimizer\n",
    "model = SimpleTransformer(embed_size, sequence_length, vocab_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optionally introduce weight decay\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Generating data\n",
    "char_to_index, inputs, targets = generate_data(num_samples, seq, sequence_length)\n",
    "\n",
    "# Create a TensorDataset to hold the inputs and targets\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4340c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12,  7,  ..., 10, 13, 10],\n",
       "        [ 2,  3,  5,  ...,  2,  5, 10],\n",
       "        [ 3,  3, 13,  ...,  7,  0,  2],\n",
       "        ...,\n",
       "        [ 9,  6,  9,  ...,  4,  4,  5],\n",
       "        [12,  9,  0,  ...,  0,  3,  0],\n",
       "        [ 2, 11,  3,  ..., 10, 13, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e707c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  7,  9,  ..., 13, 10,  6],\n",
       "        [ 3,  5,  2,  ...,  5, 10,  3],\n",
       "        [ 3, 13,  4,  ...,  0,  2,  9],\n",
       "        ...,\n",
       "        [ 6,  9,  3,  ...,  4,  5, 12],\n",
       "        [ 9,  0,  8,  ...,  3,  0, 10],\n",
       "        [11,  3,  7,  ..., 13, 10,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_per_epoch = []\n",
    "\n",
    "# Optionally introduce gradient clipping\n",
    "# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_batch, target_batch in dataloader:\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_batch)\n",
    "        loss = loss_fn(output.view(-1, vocab_size), target_batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.6f}\")\n",
    "    losses_per_epoch.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sequence\n",
    "_, sample_sequence = string_list_to_char_tensor(['4.8.;13.11.('], char_to_index, sequence_length)\n",
    "sample_tensor = (\n",
    "    torch.tensor(sample_sequence.numpy()[0], dtype=torch.long).unsqueeze(0).to(device)\n",
    ")  # Add batch dimension and send to device\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    predictions = model(sample_tensor)\n",
    "    predicted_index = predictions.argmax(\n",
    "        -1\n",
    "    )  # Get the index of the max log-probability for the last position\n",
    "\n",
    "predicted_number = predicted_index[0, -1].item()  # Convert to Python number\n",
    "print(f\"Input Sequence: {sample_sequence}\")\n",
    "print(f\"Predicted Next Number: {predicted_number}\")\n",
    "\n",
    "if plot_training_loss:\n",
    "    plt.plot(losses_per_epoch)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae4fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49975e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e569ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ff108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
